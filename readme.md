# ğŸ§  K-Nearest Neighbors (KNN) â€“ From Scratch & Using Scikit-Learn

This repository provides a complete implementation of the **K-Nearest Neighbors (KNN)** algorithm:

- âœ… Using Scikit-Learn
- âœ… Implemented From Scratch (NumPy based)
- âœ… Classification
- âœ… Regression
- âœ… Distance Metrics Comparison
- âœ… Performance Evaluation

---

## ğŸ“Œ About KNN

K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for:

- ğŸ”¹ Classification  
- ğŸ”¹ Regression  

It is a lazy learning algorithm that makes predictions based on the similarity (distance) between data points.

Instead of learning a model during training, KNN stores the dataset and performs computation at prediction time.

---

## ğŸ“‚ Project Structure

ğŸ“¦ knn-from-scratch-and-sklearn
â”£ ğŸ“œ knn using sklearm.ipynb
â”£ ğŸ“œ knn_from_scratch.py


---

## âš™ï¸ Implementation Details

### 1ï¸âƒ£ KNN Using Scikit-Learn

- sklearn.neighbors.KNeighborsClassifier
- sklearn.neighbors.KNeighborsRegressor
- Model training
- Prediction
- Accuracy calculation
- Confusion matrix

---

### 2ï¸âƒ£ KNN From Scratch

Manually implemented using:

- Euclidean Distance
- Manhattan Distance
- Majority Voting (for classification)
- Mean Averaging (for regression)

### Steps:

1. Calculate distance between test point and all training points
2. Sort distances
3. Select K nearest neighbors
4. Perform voting (classification) or averaging (regression)

---

## ğŸ“Š Distance Metrics Used

- Euclidean Distance
- Manhattan Distance
- Minkowski Distance

---

## ğŸ“ˆ Evaluation Metrics

### For Classification:

- Accuracy
- Precision
- Recall
- F1 Score
- Confusion Matrix

---

## ğŸ‘¨â€ğŸ’» Author  
**Mohd Uzaif**  
ğŸ“ *M.Tech (AI & ML), Jamia Millia Islamia University*   
---
